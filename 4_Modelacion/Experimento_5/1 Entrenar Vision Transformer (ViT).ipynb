{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2myBs4vwR_J"
   },
   "source": [
    "**Función:** entrenamiento de Visual Transformer (ViT), con el dataset 10k desbalanceado y recortado a 224x224.\n",
    "\n",
    "Se utiliza la versión [vit-base-patch16-224-in21k](https://huggingface.co/google/vit-base-patch16-224-in21k) del transformer, ya pré-entrenada con 14 millones de imagenes en 21.843 clases.\n",
    "\n",
    "**Requiere:**\n",
    "- ../../datasets/flat_10k_224/ (con una carpeta por label y las fotos recortadas)\n",
    "\n",
    "**Crea:** Fichero con el modelo entrenado (epoch con menor val_loss).\n",
    "- modelos/tf_model_\\<run_id\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9aseRNKml3g"
   },
   "outputs": [],
   "source": [
    "# !pip install mlflow\n",
    "!pip install datasets==2.4.0\n",
    "!pip install transformers[tf-cpu]\n",
    "!pip3 install --upgrade requests\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1663795342417,
     "user": {
      "displayName": "Pedro Tavares Silva",
      "userId": "15176343071283963792"
     },
     "user_tz": -120
    },
    "id": "e9UpSOpbk9Iq"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "from tensorflow.random import set_seed\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejecutadoEnGoogleDrive = False # True si se ejecuta en Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Projetos_dev/projetos/clasificacion_imagenes/1_Setup_MLOps\n"
     ]
    }
   ],
   "source": [
    "if ejecutadoEnGoogleDrive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PATH = '/content/drive/clasificacion_imagenes/'\n",
    "    ruta_dataset = '/content/drive/clasificacion_imagenes/datasets/flat_10k_224/'\n",
    "else:\n",
    "    PATH = '../../1_Setup_MLOps'\n",
    "    ruta_dataset = '../../datasets/flat_10k_224/'\n",
    "\n",
    "%cd {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1663792671822,
     "user": {
      "displayName": "Pedro Tavares Silva",
      "userId": "15176343071283963792"
     },
     "user_tz": -120
    },
    "id": "SJ04WQHdwDnp"
   },
   "outputs": [],
   "source": [
    "seed(42) # So long and thanks for all the fish\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.require(\"datasets==2.4.0\")\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_X33WVAwR_T"
   },
   "source": [
    "# Definir experimento y run (MLflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir quién está ejecutando (para no machacar el MLflow de los compañeros)\n",
    "# Descomentar la linea que aplique\n",
    "# yo = 'Pedro_T'\n",
    "# yo = 'Toni_V'\n",
    "# yo = 'Carlos_H'\n",
    "# yo = 'Carlos_C'\n",
    "print('Notebook ejecutado por {}'.format(yo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2716,
     "status": "ok",
     "timestamp": 1663792715513,
     "user": {
      "displayName": "Pedro Tavares Silva",
      "userId": "15176343071283963792"
     },
     "user_tz": -120
    },
    "id": "WXCoFIaxneg2",
    "outputId": "262478fe-c33f-4689-d25c-8c5dae33f7f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/24 16:55:20 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos empezar el run 6f10e94880f04b52b45b77217ba5925d en el experimento 4. Este run está RUNNING.\n"
     ]
    }
   ],
   "source": [
    "# Este run pertenence al experimento 5, que tiene el id \"4\" (string)\n",
    "experiment_id = \"4\"\n",
    "mlflow.set_experiment(experiment_id = experiment_id) \n",
    "run = mlflow.start_run( # crear run en MLflow\n",
    "    experiment_id=experiment_id,\n",
    "    tags={\"Autor\": yo, 'Arquitectura':'google/vit-base-patch16-224-in21k'}\n",
    ")\n",
    "# activar auto logging\n",
    "mlflow.tensorflow.autolog()\n",
    "print('Vamos empezar el run {} en el experimento {}. Este run está {}.'.format(run.info.run_id, experiment_id, run.info.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reanudar\n",
    "experiment_id = \"4\"\n",
    "run = mlflow.start_run(run_id='6f10e94880f04b52b45b77217ba5925d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/25 10:00:08 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos empezar el run 6f10e94880f04b52b45b77217ba5925d en el experimento 4. Este run está RUNNING.\n"
     ]
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog()\n",
    "print('Vamos empezar el run {} en el experimento {}. Este run está {}.'.format(run.info.run_id, experiment_id, run.info.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/25/2022 10:00:15 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
      "09/25/2022 10:00:15 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=Experimento_5/modelos/runs/Sep25_10-00-14_658e50a237bd,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "output_dir=Experimento_5/modelos/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=['mlflow', 'tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=Experimento_5/modelos/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f503911b09b640338a656dfe7c854f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/8312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/25/2022 10:00:19 - WARNING - datasets.builder - Using custom data configuration default-b8c6bbfc7a1635cf\n",
      "Downloading and preparing dataset imagefolder/default to /root/.cache/huggingface/datasets/imagefolder/default-b8c6bbfc7a1635cf/0.0.0/0fc50c79b681877cc46b23245a6ef5333d036f48db40d53765a68034bc48faff...\n",
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9501caac5f924d49b44197d34c1e7a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #10:   0%|          | 0/519 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668257ca4c304bd49ca971ae0c4c2618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #0:   0%|          | 0/520 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9849509e1f354e6e8be5ded6f154eea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #8:   0%|          | 0/519 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6ec76500fa4e8981f9860155edcb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #13:   0%|          | 0/519 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8489676bcde24d30b00d020a580f98ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #9:   0%|          | 0/519 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee6d17bd3b140d686e0fed2fe4ea4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #11:   0%|          | 0/519 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923e70fea9a243d69c1450619147ad0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #3:   0%|          | 0/520 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd9177c30ab44998f94e8775e7a33cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #1:   0%|          | 0/520 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba37feb1babb4c97856e27c6b58bf9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #2:   0%|          | 0/520 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234429caf20c4846bff995ad7db13055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #4:   0%|          | 0/520 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39463a8ba1994dc5ae92964cad21afb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #7:   0%|          | 0/520 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb9f29333f74aedb27fe0d3a7c1de29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #12:   0%|          | 0/519 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e91accc56ec42b1be48f02aa900370b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #5:   0%|          | 0/520 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e97b55c1854b999d1bf00a544591cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #14:   0%|          | 0/519 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992bf6f6afe44ab5b6cc5d3cf1b9fd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #15:   0%|          | 0/519 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1989b693e70d4075901c5dc0d13a910b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #6:   0%|          | 0/520 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4e6f4e4da94fdc99a336b70126592f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dca7e827a844620b9dd58d48a6b7900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /root/.cache/huggingface/datasets/imagefolder/default-b8c6bbfc7a1635cf/0.0.0/0fc50c79b681877cc46b23245a6ef5333d036f48db40d53765a68034bc48faff. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761168aa51c349228d76c0c03c9772cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c844227956f94b08a87ef94a005a9ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5ed9ab37804676b07b41478e522f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc4c3b89e8f488f85e5c7b5b435b7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:648] 2022-09-25 10:00:24,844 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/1ba429d32753f33a0660b80ac6f43a3c80c18938/config.json\n",
      "[INFO|configuration_utils.py:700] 2022-09-25 10:00:24,846 >> Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"finetuning_task\": \"image-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"drink\",\n",
      "    \"1\": \"food\",\n",
      "    \"2\": \"inside\",\n",
      "    \"3\": \"menu\",\n",
      "    \"4\": \"outside\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"drink\": \"0\",\n",
      "    \"food\": \"1\",\n",
      "    \"inside\": \"2\",\n",
      "    \"menu\": \"3\",\n",
      "    \"outside\": \"4\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.22.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cea5e850cfa4048a090c0cd72ffe7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:2084] 2022-09-25 10:00:33,505 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/1ba429d32753f33a0660b80ac6f43a3c80c18938/pytorch_model.bin\n",
      "[WARNING|modeling_utils.py:2513] 2022-09-25 10:00:34,847 >> Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:2525] 2022-09-25 10:00:34,850 >> Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2656a3fde1704d819936b0d7c3163eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|feature_extraction_utils.py:437] 2022-09-25 10:00:35,761 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/1ba429d32753f33a0660b80ac6f43a3c80c18938/preprocessor_config.json\n",
      "[INFO|configuration_utils.py:648] 2022-09-25 10:00:36,176 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/1ba429d32753f33a0660b80ac6f43a3c80c18938/config.json\n",
      "[INFO|configuration_utils.py:700] 2022-09-25 10:00:36,178 >> Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.22.1\"\n",
      "}\n",
      "\n",
      "[INFO|feature_extraction_utils.py:474] 2022-09-25 10:00:36,181 >> Feature extractor ViTFeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"size\": 224\n",
      "}\n",
      "\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1628] 2022-09-25 10:00:36,262 >> ***** Running training *****\n",
      "[INFO|trainer.py:1629] 2022-09-25 10:00:36,262 >>   Num examples = 7065\n",
      "[INFO|trainer.py:1630] 2022-09-25 10:00:36,263 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1631] 2022-09-25 10:00:36,264 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1632] 2022-09-25 10:00:36,265 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1633] 2022-09-25 10:00:36,266 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1634] 2022-09-25 10:00:36,267 >>   Total optimization steps = 2652\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2652' max='2652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2652/2652 3:18:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.116200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2669] 2022-09-25 10:40:35,052 >> Saving model checkpoint to Experimento_5/modelos/checkpoint-500\n",
      "[INFO|configuration_utils.py:442] 2022-09-25 10:40:35,088 >> Configuration saved in Experimento_5/modelos/checkpoint-500/config.json\n",
      "[INFO|modeling_utils.py:1583] 2022-09-25 10:40:46,989 >> Model weights saved in Experimento_5/modelos/checkpoint-500/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:341] 2022-09-25 10:40:47,010 >> Feature extractor saved in Experimento_5/modelos/checkpoint-500/preprocessor_config.json\n",
      "[INFO|trainer.py:2669] 2022-09-25 11:19:44,584 >> Saving model checkpoint to Experimento_5/modelos/checkpoint-1000\n",
      "[INFO|configuration_utils.py:442] 2022-09-25 11:19:44,599 >> Configuration saved in Experimento_5/modelos/checkpoint-1000/config.json\n",
      "[INFO|modeling_utils.py:1583] 2022-09-25 11:19:46,988 >> Model weights saved in Experimento_5/modelos/checkpoint-1000/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:341] 2022-09-25 11:19:47,002 >> Feature extractor saved in Experimento_5/modelos/checkpoint-1000/preprocessor_config.json\n",
      "[INFO|trainer.py:2669] 2022-09-25 11:54:14,430 >> Saving model checkpoint to Experimento_5/modelos/checkpoint-1500\n",
      "[INFO|configuration_utils.py:442] 2022-09-25 11:54:14,443 >> Configuration saved in Experimento_5/modelos/checkpoint-1500/config.json\n",
      "[INFO|modeling_utils.py:1583] 2022-09-25 11:54:17,058 >> Model weights saved in Experimento_5/modelos/checkpoint-1500/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:341] 2022-09-25 11:54:17,072 >> Feature extractor saved in Experimento_5/modelos/checkpoint-1500/preprocessor_config.json\n",
      "[INFO|trainer.py:2669] 2022-09-25 12:28:59,870 >> Saving model checkpoint to Experimento_5/modelos/checkpoint-2000\n",
      "[INFO|configuration_utils.py:442] 2022-09-25 12:28:59,884 >> Configuration saved in Experimento_5/modelos/checkpoint-2000/config.json\n",
      "[INFO|modeling_utils.py:1583] 2022-09-25 12:29:01,941 >> Model weights saved in Experimento_5/modelos/checkpoint-2000/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:341] 2022-09-25 12:29:01,953 >> Feature extractor saved in Experimento_5/modelos/checkpoint-2000/preprocessor_config.json\n",
      "[INFO|trainer.py:2669] 2022-09-25 13:06:45,094 >> Saving model checkpoint to Experimento_5/modelos/checkpoint-2500\n",
      "[INFO|configuration_utils.py:442] 2022-09-25 13:06:45,108 >> Configuration saved in Experimento_5/modelos/checkpoint-2500/config.json\n",
      "[INFO|modeling_utils.py:1583] 2022-09-25 13:06:47,471 >> Model weights saved in Experimento_5/modelos/checkpoint-2500/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:341] 2022-09-25 13:06:47,551 >> Feature extractor saved in Experimento_5/modelos/checkpoint-2500/preprocessor_config.json\n",
      "[INFO|trainer.py:1873] 2022-09-25 13:19:02,196 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2669] 2022-09-25 13:19:02,773 >> Saving model checkpoint to Experimento_5/modelos/\n",
      "[INFO|configuration_utils.py:442] 2022-09-25 13:19:02,788 >> Configuration saved in Experimento_5/modelos/config.json\n",
      "[INFO|modeling_utils.py:1583] 2022-09-25 13:19:05,593 >> Model weights saved in Experimento_5/modelos/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:341] 2022-09-25 13:19:05,605 >> Feature extractor saved in Experimento_5/modelos/preprocessor_config.json\n",
      "[INFO|trainer.py:2920] 2022-09-25 13:19:05,664 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2922] 2022-09-25 13:19:05,665 >>   Num examples = 1247\n",
      "[INFO|trainer.py:2925] 2022-09-25 13:19:05,667 >>   Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =          3.0\n",
      "  total_flos               = 1529685111GF\n",
      "  train_loss               =       0.2075\n",
      "  train_runtime            =   3:18:25.92\n",
      "  train_samples_per_second =         1.78\n",
      "  train_steps_per_second   =        0.223\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 04:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_accuracy           =     0.9679\n",
      "  eval_loss               =     0.1228\n",
      "  eval_runtime            = 0:04:53.66\n",
      "  eval_samples_per_second =      4.246\n",
      "  eval_steps_per_second   =      0.531\n"
     ]
    }
   ],
   "source": [
    "%run Experimento_5/run_image_classification.py\\\n",
    "--train_dir {ruta_dataset}\\\n",
    "--output_dir Experimento_5/modelos/\\\n",
    "--remove_unused_columns False\\\n",
    "--do_train\\\n",
    "--do_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwY9ODGfwR_X"
   },
   "source": [
    "# Predicir con el modelo tuneado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hp-6MgdNwR_Y",
    "outputId": "9affb475-6790-48a0-e7d4-5854a7d3f643"
   },
   "outputs": [],
   "source": [
    "model.save('../4_Modelacion/Experimento_5/modelos/tf_model_exp1_{}'.format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xu8vkTDJwR_Y"
   },
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
